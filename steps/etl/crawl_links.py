"""
For parsing URLs.*|>
*|>Parsing URLs is essential in web crawling and ETL processes because it allows you to break down a URL into its components.
It is used to extract components such as the scheme, netloc, path, etc.
Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø± Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø±Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¯Ø³ØªÚ©Ø§Ø±ÛŒ ÛŒÙˆ Ø§Ø± Ø§Ù„ Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
ØªØ§ Ø¨ØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø¬Ø²Ø§ÛŒ Ù…Ø®ØªÙ„Ù ÛŒÚ© ÛŒÙˆ Ø§Ø± Ø§Ù„ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯
"""
from asyncore import dispatcher
from urllib.parse import urlparse
"""
Importing logger for logging purposes.*|>
|>Logging is crucial for monitoring the execution of ETL processes, *|> 
*|>debugging issues, and keeping track of the workflow.
ETL means Extract, Transform, Load, which is a common process in data engineering.
Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù„Ø§Ú¯ÙˆØ±Ùˆ ÛŒÚ© Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯  Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª ÙˆÙ‚Ø§ÛŒØ¹ Ø¯Ø± Ù¾Ø§ÛŒØªÙˆÙ†
Ø§Ø³Øª Ú©Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ù† Ø±Ø§ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯ØªØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
Ù‡Ù…Ú†Ù†ÛŒÙ† Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØ§ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ØŒ
Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø·Ø­ Ù„Ø§Ú¯ÛŒÙ†Ú¯ØŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ù‡ Ú†Ù†Ø¯ÛŒÙ† Ù…Ù‚ØµØ¯ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
"""
from loguru import Logger, logger
from tqdm import tqdm
"""
For type annotations.*|>
*|>Type annotations help in improving code readability and maintainability.
Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¨Ù‡ Ø´Ù…Ø§ Ø§Ù…Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ØªØ§ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªÙˆØ§Ø¨Ø¹ Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯
Ùˆ Ø¨Ù‡ Ø§ÛŒÙ† ØªØ±ØªÛŒØ¨ Ú©Ø¯ Ø´Ù…Ø§ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù…â€ŒØªØ± Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¢Ù† Ø¢Ø³Ø§Ù†â€ŒØªØ± Ù…ÛŒâ€ŒØ´ÙˆØ¯.
"""
from typing_extensions import Annotated
"""
ZenML imports.*|>
*|>ZenML is a machine learning operations (MLOps) framework that helps
streamline the process of building, deploying, and maintaining machine learning models.
It provides tools and abstractions to manage the entire machine learning lifecycle,
from data ingestion to model deployment and monitoring.
Ø§ÛŒÙ† ÛŒÚ© ÙØ±ÛŒÙ…â€ŒÙˆØ±Ú© Ø¹Ù…Ù„ÛŒØ§Øª ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø§Ù… Ø§Ù„ Ø§Ù¾Ø³ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø³Ø§Ø®ØªØŒ
Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
Ø§ÛŒÙ† ÙØ±ÛŒÙ…â€ŒÙˆØ±Ú© Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ Ø§Ù†ØªØ²Ø§Ø¹â€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ Ú†Ø±Ø®Ù‡ Ø¹Ù…Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†ØŒ
Ø§Ø² Ø¬Ø°Ø¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªØ§ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ù…Ø¯Ù„ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
"""
from zenml import get_step_context, step
"""
CrawlerDispatcher 
ÛŒÙ‡ Ú©Ù„Ø§Ø³ Ù…Ø±Ú©Ø²ÛŒ 
(Dispatcher pattern) 
Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†ÙˆØ§Ø¹ 
crawler Ù‡Ø§Ø³Øª.
ÙØ±Ø¶ Ú©Ù† Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÛŒ 
LLM Twin Ù…ÛŒâ€ŒØ®ÙˆØ§Ø¯ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ù…Ù†Ø¨Ø¹ 
(LinkedInØŒ MediumØŒ GitHubØŒ TwitterØŒ ...) Ø¯Ø§Ø¯Ù‡ Ø¬Ù…Ø¹ Ú©Ù†Ù‡.
Ø¨Ù‡â€ŒØ¬Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ù†Ø¨Ø¹ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ú©Ø¯ Ø¨Ù†ÙˆÛŒØ³Ù‡ØŒ
ÛŒÚ© Dispatcher ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ú©Ù‡ Ù…ÛŒâ€ŒÚ¯Ù‡:
Ù„ÛŒÙ†Ú© Ø±Ùˆ Ø¨Ø¯Ù‡ Ù…Ù†ØŒ Ø®ÙˆØ¯Ù… ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù… Ø§Ø² Ú†Ù‡ Ù†ÙˆØ¹ÛŒÙ‡ Ùˆ Ø¨Ø§ Ú©Ø¯ÙˆÙ… crawler Ø¨Ø§ÛŒØ¯ Ø®ÙˆÙ†Ø¯Ù‡ Ø¨Ø´Ù‡.
"""
from llm_engineering.application.crawlers.dispatcher import CrawlerDispatcher
"""
Ø¨ÙˆØ²Ø± Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª ÛŒÚ© Ù…Ø¯Ù„ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ (Ù…Ø§Ù†Ù†Ø¯ Ù…ÙˆÙ†Ú¯Ùˆ) Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø± ØªÙ…ÛŒØ² Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ØŒ Ø¨Ø®Ø´ Â«Ù‡Ø³ØªÙ‡ Ù…Ù†Ø·Ù‚ÛŒÂ» Ø¬Ø§ÛŒÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ…ØŒ Ù…Ø§Ù†Ù†Ø¯ Ú©Ø§Ø±Ø¨Ø±ØŒ ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.

Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ØŒ ØªÙ…Ø§Ù… Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± (Ù…Ø«Ù„ Ù†Ø§Ù…ØŒ Ù…Ø¹Ø±ÙÛŒØŒ Ùˆ Ù¾ÛŒÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ) Ø¯Ø± Ù‚Ø§Ù„Ø¨ UserDocument Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

ğŸ’¡ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø± Ø§ÛŒÙ† Ú¯Ø§Ù…:
Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ø®Ø²Ù†Ø¯Ù‡ Ø§Ø² Ù¾ÛŒÙˆÙ†Ø¯Ù‡Ø§ Ø¯Ø§Ø¯Ù‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø¨Ø§ÛŒØ¯ Ø¨Ø¯Ø§Ù†Ø¯ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡ Ú©Ø¯Ø§Ù… Ú©Ø§Ø±Ø¨Ø± Ø§Ø³Øª.
Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø¯Ù„ÛŒÙ„ØŒ user: UserDocument Ø¨Ù‡ ZenML Ø§Ø·Ù„Ø§Ø¹ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡:

Â«Ù…Ù† Ø¯Ø± Ø­Ø§Ù„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÛŒÙ† Ú©Ø§Ø±Ø¨Ø± Ø®Ø§Øµ Ù‡Ø³ØªÙ…Ø› Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ù‡Ù…Ø§Ù† Ú©Ø§Ø±Ø¨Ø± Ù…ØªØµÙ„ Ú©Ù†.Â»    
"""
from llm_engineering.domain.documents import UserDocument

"""
ÛŒØ¹Ù†ÛŒ ØªÙˆ Ø¨Ù‡ Ø§ÛŒÙ† Ú¯Ø§Ù… Ø§Ø² Ø®Ø· Ù„ÙˆÙ„Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒ:
Ø¨Ø±Ùˆ Ø§ÛŒÙ† Ø¯Ùˆ ØªØ§ Ù„ÛŒÙ†Ú© Ø±Ùˆ Ø¨Ø±Ø§Ù… Ø¨Ø®ÙˆÙ†.
Ù‡Ø±Ú†ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡Ø³Øª (Ù…ØªÙ† Ù…Ù‚Ø§Ù„Ù‡ØŒ ØªÙˆØ¶ÛŒØ­ Ù¾Ø±ÙˆÚ˜Ù‡ Ùˆ...) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ØŒ
ÙˆÙ„ÛŒ ÛŒØ§Ø¯Øª Ø¨Ø§Ø´Ù‡ Ø§ÛŒÙ†Ø§ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆÙ†Ø§ Ø­Ø³ÛŒÙ†ÛŒ Ù‡Ø³ØªÙ†.
"""
#crawl_links(user=mona, links=["https://medium.com/@mona/article1", "https://github.com/mona/project1"])
@step
def crawl_links(user: UserDocument, links: list[str]) -> Annotated[list[str], "crawled_links"]:

    return[]