from turtle import st
from loguru import logger
"""
Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ù‚Ø¯Ø§Ø± Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ù…Ø«Ù„ Ø¢Ø¯Ø±Ø³ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒØ¯Ø§Ø¯Ù‡ØŒ Ú©Ù„ÛŒØ¯ Ø¯Ø³ØªØ±Ø³ÛŒ Ùˆ Ø±Ù…Ø²Ù‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯
Ùˆ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© Ù…Ø¯Ù„ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø³Ø§Ø®Øªâ€ŒÛŒØ§ÙØªÙ‡ Ùˆ Ù‚Ø§Ø¨Ù„ Ú©Ù†ØªØ±Ù„ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
Ø¨Ù‡ Ø§ÛŒÙ† ØªØ±ØªÛŒØ¨ Ù†ÛŒØ§Ø²ÛŒ Ù†ÛŒØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§ Ø¯Ø³ØªÛŒ ØªØ¹Ø±ÛŒÙ ÛŒØ§ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø®ÙˆØ§Ù†ÛŒØ›
Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ù…Ø±ØªØ¨ØŒ Ø§ÛŒÙ…Ù† Ùˆ ÛŒÚ©â€ŒØ¬Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯    
"""
from pydantic_settings import BaseSettings, SettingsConfigDict
from zenml.client import Client
from zenml.exceptions import EntityExistsError

class Settings(BaseSettings):
    # SettingsConfigDict is used to configure pydantic settings behavior,
    # such as specifying an environment file to load variables from.
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8")

# --- Required settings even when working locally. ---

    #OpenAI API.
    OPENAI_MODEL_ID: str = "gpt-40-mini"
    # OpenAI API key for accessing OpenAI services.
    OPENAI_API_KEY: str | None = None

    #HuggingFace API.
    HUGGINGFACE_API_KEY: str | None = None

    #Comet ML (during training).
    # Comet ML is used for experiment tracking and model monitoring.
    COMET_API_KEY: str | None = None
    COMET_PROJECT_NAME: str = "twin"

    # --- Required settings when deploying the code. ---
    # --- Otherwise, default values values work fine. ---

    #MongoDB database settings.
    DATABASE_HOST: str = "mongodb://localhost:27017"
    DATABASE_NAME: str = "twin"

    #Qdrant vector database settings.
    USE_QDRANT_CLOUD: bool = False                  # Whether to use Qdrant Cloud or local instance.
    QDRANT_DATABASE_HOST: str = "localhost"         # Hostname for local Qdrant instance.
    QDRANT_DATABASE_PORT: int = 6333
    QDRANT_CLOUD_URL: str = "str"                   # URL for local or cloud Qdrant instance.
    QDRANT_APIKEY: str | None = None                # API key for local or cloud Qdrant instance.

    # AWS Authentication.
    AWS_REGION: str = "eu-central-1"
    AWS_ACCESS_KEY: str | None = None
    AWS_SECRET_KEY: str | None = None
    AWS_ARN_ROLE: str | None = None

    # --- Optional settings used to tweak the code. ---

    #AWS SageMaker settings.
    HF_MODEL_ID: str = "mlabonne/TwinLlama-3.1-8B-DPO"   # HuggingFace model ID for SageMaker deployment.
    GPU_INSTANCE_TYPE: str = "ml.g5.2xlarge"             # GPU instance type for SageMaker deployment.
    SM_NUM_GPUS: int = 1                                 # Number of GPUs for SageMaker instance.
    MAX_INPUT_LENGTH: int = 2048                         # Maximum input length for the model.
    MAX_TOTAL_TOKENS: int = 4096                         # Maximum total tokens (input + output).
    COPIES: int = 1                                      # Number of model copies to deploy.
    GPUS: int = 1                                        # Number of GPUs to use.
    CPUS: int = 2                                        # Number of CPUs to use.

    """ ____________AWS SageMaker inference settings_____________. 
Temperature, Top-p, and Max New Tokens â€” Generation Controls
-------------------------------------------------------------

English Explanation:
These parameters control the creativity, determinism, and length of generated text.
- temperature: Controls randomness. Lower = more focused and factual; higher = more creative and diverse.
- top_p: Limits the cumulative probability of token sampling. A smaller value restricts choices to the most likely words.
- max_new_tokens: Defines the maximum number of tokens the model can generate in one response.

Example:
For temperature=0.01, top_p=0.9, max_new_tokens=150:
â†’ The model produces logical, precise, and extended answers â€” ideal for technical or analytical contexts.

-------------------------------------------------------------

ØªÙˆØ¶ÙŠØ­ ÙØ§Ø±Ø³ÙŠ:
Ø§ÙŠÙ† Ø³Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù…ÙŠØ²Ø§Ù† Ø®Ù„Ø§Ù‚ Ø¨ÙˆØ¯Ù†ØŒ Ù‚Ø§Ø¨Ù„ Ù¾ÙŠØ´â€ŒØ¨ÙŠÙ†ÙŠ Ø¨ÙˆØ¯Ù† Ùˆ Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÙŠ Ø±Ø§ ØªØ¹ÙŠÙŠÙ† Ù…ÙŠâ€ŒÙƒÙ†Ù†Ø¯.
- Ø¯Ù…Ø§ (temperature): Ù…ÙŠØ²Ø§Ù† ØªØµØ§Ø¯ÙÙŠ Ø¨ÙˆØ¯Ù† ØªÙˆÙ„ÙŠØ¯ Ø±Ø§ Ù…Ø´Ø®Øµ Ù…ÙŠâ€ŒÙƒÙ†Ø¯. Ø¹Ø¯Ø¯ ÙƒÙ…â€ŒØªØ± ÙŠØ¹Ù†ÙŠ Ù¾Ø§Ø³Ø® Ù…Ù†Ø·Ù‚ÙŠâ€ŒØªØ± Ùˆ Ø¹Ù„Ù…ÙŠâ€ŒØªØ±ØŒ Ø¹Ø¯Ø¯ Ø¨Ø§Ù„Ø§ØªØ± ÙŠØ¹Ù†ÙŠ Ù¾Ø§Ø³Ø® Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡â€ŒØªØ± Ùˆ ØºÙŠØ±Ù‚Ø§Ø¨Ù„ Ù¾ÙŠØ´â€ŒØ¨ÙŠÙ†ÙŠâ€ŒØªØ±.
- Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø±Ø´ (top_p): Ù…Ø­Ø¯ÙˆØ¯Ù‡â€ŒÙŠ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù†ØªØ®Ø§Ø¨ ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ Ø±Ø§ ØªØ¹ÙŠÙŠÙ† Ù…ÙŠâ€ŒÙƒÙ†Ø¯. Ù‡Ø±Ú†Ù‡ ÙƒÙ…â€ŒØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ù…Ø¯Ù„ ÙÙ‚Ø· Ø§Ø² Ø¨ÙŠÙ† ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÙŠ Ù…Ø¹Ù‚ÙˆÙ„â€ŒØªØ± Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙŠâ€ŒÙƒÙ†Ø¯.
- Ø­Ø¯Ø§ÙƒØ«Ø± ØªÙˆÙƒÙ† Ø¬Ø¯ÙŠØ¯ (max_new_tokens): Ø­Ø¯Ø§ÙƒØ«Ø± ØªØ¹Ø¯Ø§Ø¯ ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÙŠÙŠ ÙƒÙ‡ Ù…Ø¯Ù„ Ø¯Ø± ÙŠÙƒ Ù¾Ø§Ø³Ø® ØªÙˆÙ„ÙŠØ¯ Ù…ÙŠâ€ŒÙƒÙ†Ø¯ Ø±Ø§ Ù…Ø´Ø®Øµ Ù…ÙŠâ€ŒÙƒÙ†Ø¯.

Ù†Ù…ÙˆÙ†Ù‡:
ÙˆÙ‚ØªÙŠ Ø¯Ù…Ø§ Û°Ù«Û°Û±ØŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø¨Ø±Ø´ Û°Ù«Û¹ Ùˆ Ø­Ø¯Ø§ÙƒØ«Ø± ØªÙˆÙƒÙ† Û±ÛµÛ° Ø¨Ø§Ø´Ø¯ØŒ
Ù…Ø¯Ù„ Ù¾Ø§Ø³Ø®ÙŠ Ø¯Ù‚ÙŠÙ‚ØŒ Ù…Ù†Ø·Ù‚ÙŠ Ùˆ Ù†Ø³Ø¨ØªØ§Ù‹ Ø·ÙˆÙ„Ø§Ù†ÙŠ ØªÙˆÙ„ÙŠØ¯ Ù…ÙŠâ€ŒÙƒÙ†Ø¯ ÙƒÙ‡ Ø¨Ø±Ø§ÙŠ Ù…ØªÙ†â€ŒÙ‡Ø§ÙŠ ÙÙ†ÙŠ Ùˆ ØªØ­Ù„ÙŠÙ„ÙŠ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.

    """
    SAGEMAKER_ENDPOINT_CONFIG_INFERENCE: str = "twin"    # It is the SageMaker endpoint configuration name for inference.
    SAGEMAKER_ENDPOINT_INFERENCE: str = "twin"           # It is the SageMaker endpoint name for inference.
    
    TEMPERATURE_INFERENCE: float = 0.01                  # Temperature setting for inference. It controls randomness means of output.
                                                         # Higher values like 0.8 will make the output more random,
                                                         # while lower values like 0.2 will make it more focused and deterministic.
    
    TOP_P_INFERENCE: float = 0.9                         # Top-p (nucleus) sampling parameter for inference.
                                                         # It considers the smallest set of tokens whose cumulative probability
                                                         # exceeds the threshold p. This helps in generating more coherent and contextually relevant text.
    
    MAX_NEW_TOKENS_INFERENCE: int = 150                  # Maximum new tokens to generate during inference.

    """
RAG (Retrieval-Augmented Generation) Configuration
--------------------------------------------------

English Explanation:
These settings define the models and device used for the RAG pipeline.
RAG enhances an LLM by combining retrieval and generation â€” first fetching
relevant context from a vector database (e.g., Qdrant), then generating
an informed and grounded response.

- TEXT_EMBEDDING_MODEL_ID: The embedding model used to convert text into vectors for similarity search.
- RERANKING_CROSS_ENCODER_MODEL_ID: A re-ranking model that scores and orders retrieved documents.
- RAG_MODEL_DEVICE: The hardware used for inference, usually "cpu" or "cuda".

Example Flow:
Query â†’ Embedding â†’ Retrieve top matches â†’ Re-rank â†’ Inject into LLM prompt â†’ Generate answer.

--------------------------------------------------

ØªÙˆØ¶ÙŠØ­ ÙØ§Ø±Ø³ÙŠ:
Ø§ÙŠÙ† ØªÙ†Ø¸ÙŠÙ…Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚ÙˆÙŠØªâ€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ø¨Ø§Ø²ÙŠØ§Ø¨ÙŠ Ø§Ø³Øª (RAG).
Ø¯Ø± Ø§ÙŠÙ† Ø±ÙˆØ´ØŒ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÙŠ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÙŠ Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ø§Ø² Ù¾Ø§ÙŠÚ¯Ø§Ù‡ Ø¨Ø±Ø¯Ø§Ø±ÙŠ (Ù…Ø§Ù†Ù†Ø¯ Qdrant) Ø¬Ø³Øªâ€ŒÙˆØ¬Ùˆ Ù…ÙŠâ€ŒÙƒÙ†Ø¯
Ùˆ Ø³Ù¾Ø³ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù¾Ø§Ø³Ø® Ø¢Ú¯Ø§Ù‡Ø§Ù†Ù‡ Ùˆ Ù…Ø¨ØªÙ†ÙŠ Ø¨Ø± Ø­Ù‚ÙŠÙ‚Øª ØªÙˆÙ„ÙŠØ¯ Ù…ÙŠâ€ŒÙƒÙ†Ø¯.

- Ø´Ù†Ø§Ø³Ù‡â€ŒÙŠ Ù…Ø¯Ù„ ØªØ¨Ø¯ÙŠÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± (TEXT_EMBEDDING_MODEL_ID): Ù…Ø¯Ù„ÙŠ ÙƒÙ‡ Ø¬Ù…Ù„Ø§Øª Ø±Ø§ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÙŠ Ø¹Ø¯Ø¯ÙŠ ØªØ¨Ø¯ÙŠÙ„ Ù…ÙŠâ€ŒÙƒÙ†Ø¯ ØªØ§ Ø¨ØªÙˆØ§Ù† Ø´Ø¨Ø§Ù‡Øª Ù…ÙŠØ§Ù† Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø³Ù†Ø¬ÙŠØ¯.
- Ø´Ù†Ø§Ø³Ù‡â€ŒÙŠ Ù…Ø¯Ù„ Ø¨Ø§Ø²Ú†ÙŠÙ†ÙŠ (RERANKING_CROSS_ENCODER_MODEL_ID): Ù…Ø¯Ù„ÙŠ ÙƒÙ‡ Ù¾Ø³ Ø§Ø² Ø¨Ø§Ø²ÙŠØ§Ø¨ÙŠ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ù†ØªØ§ÙŠØ¬ Ø±Ø§ Ø¨Ø±Ø§Ø³Ø§Ø³ Ø§Ø±ØªØ¨Ø§Ø· Ø¯Ù‚ÙŠÙ‚â€ŒØªØ± Ù…Ø±ØªØ¨ Ù…ÙŠâ€ŒÙƒÙ†Ø¯.
- Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ø§Ø¬Ø±Ø§ (RAG_MODEL_DEVICE): ØªØ¹ÙŠÙŠÙ† Ù…ÙŠâ€ŒÙƒÙ†Ø¯ Ø§Ø¬Ø±Ø§ÙŠ Ù…Ø¯Ù„ Ø±ÙˆÙŠ Ù¾Ø±Ø¯Ø§Ø²Ù†Ø¯Ù‡â€ŒÙŠ Ù…Ø±ÙƒØ²ÙŠ ÙŠØ§ Ú¯Ø±Ø§ÙÙŠÙƒÙŠ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.

Ù†Ù…ÙˆÙ†Ù‡â€ŒÙŠ ÙØ±Ø§ÙŠÙ†Ø¯:
Ù¾Ø±Ø³Ø´ â† ØªØ¨Ø¯ÙŠÙ„ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± â† Ø¨Ø§Ø²ÙŠØ§Ø¨ÙŠ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÙŠ Ù…Ø´Ø§Ø¨Ù‡ â† Ø¨Ø§Ø²Ú†ÙŠÙ†ÙŠ â† ØªØ²Ø±ÙŠÙ‚ Ø¨Ù‡ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÙŠ â† ØªÙˆÙ„ÙŠØ¯ Ù¾Ø§Ø³Ø®
"""
    # RAG
    TEXT_EMBEDDING_MODEL_ID: str = "sentence-transformers/all-MiniLM-L6-v2"
    RERANKING_CROSS_ENCODER_MODEL_ID: str = "cross-encoder/ms-marco-MiniLM-L-4-v2"
    RAG_MODEL_DEVICE: str = "cpu"

    # LinkedIn Credentials
    LINKEDIN_USERNAME: str | None = None
    LINKEDIN_PASSWORD: str | None = None

    """
ðŸ’¡ @property
----------------------------------------
EN:
@property is used to define a method that behaves like an attribute.
It allows you to calculate or retrieve values dynamically
without calling the method with parentheses.

FA:
@property Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒÙ… ÛŒÚ© ØªØ§Ø¨Ø¹ Ù…Ø§Ù†Ù†Ø¯ ÛŒÚ© ÙˆÛŒÚ˜Ú¯ÛŒ (attribute)
Ø±ÙØªØ§Ø± Ú©Ù†Ø¯. ÛŒØ¹Ù†ÛŒ Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø§Ù†ØªØ² ØµØ¯Ø§ Ø²Ø¯Ù‡ Ø´ÙˆØ¯ ÙˆÙ„ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù¾Ø´Øª ØµØ­Ù†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¬Ø§Ù… â€ŒØ´ÙˆØ¯.
Ø§ÛŒÙ† Ø±ÙˆÛŒÚ©Ø±Ø¯ Ø¨Ø±Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ù…ÙÛŒØ¯ Ø§Ø³Øª Ú©Ù‡ Ù…Ù‚Ø¯Ø§Ø±Ø´Ø§Ù† Ø§Ø² Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

ðŸ’¡ @classmethod
----------------------------------------
EN:
@classmethod defines a method that works on the class itself, not on an instance.
It receives 'cls' instead of 'self' and is used when you need to access or modify
class-level data shared across all instances.

FA:
@classmethod Ø¨Ø±Ø§ÛŒ ØªØ¹Ø±ÛŒÙ Ù…ØªØ¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø¨Ø± Ø±ÙˆÛŒ Ø®ÙˆØ¯ Ú©Ù„Ø§Ø³ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ
Ù†Ù‡ Ø¨Ø± Ø±ÙˆÛŒ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø®Ø§Øµ Ø§Ø² Ø¢Ù†. Ø¨Ù‡â€ŒØ¬Ø§ÛŒ selfØŒ Ù¾Ø§Ø±Ø§Ù…ØªØ± cls Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
Ùˆ Ø²Ù…Ø§Ù†ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¯Ø§Ø¯Ù‡ ÛŒØ§ Ø±ÙØªØ§Ø± Ø³Ø·Ø­ Ú©Ù„Ø§Ø³ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù†ÛŒÙ…
(Ù…Ø«Ù„ Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ø³Ø§Ø®Øª Ø§Ø´ÛŒØ§Ø¡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§ØµØŒ ÛŒØ§ Ù…ØªØ¯Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø®Ø§Ù†Ù‡â€ŒØ§ÛŒ).

ðŸ’¡ @staticmethod
----------------------------------------
EN:
@staticmethod defines a method that doesn't depend on class or instance state.
Itâ€™s just a utility function placed inside a class for organizational purposes.

FA:
@staticmethod Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ØªØ¯ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ú©Ù„Ø§Ø³ ÛŒØ§ Ø´ÛŒØ¡ Ù†Ø¯Ø§Ø±Ø¯.
ØµØ±ÙØ§Ù‹ ÛŒÚ© ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ù…Ø±Ø¨ÙˆØ· Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ
Ø§Ù…Ø§ Ù…Ø³ØªÙ‚Ù„ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ú©Ù„Ø§Ø³ ÛŒØ§ Ù†Ù…ÙˆÙ†Ù‡ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """ 
    @property
    def OPEN_MAX_TOKEN_WINDOW(self) -> int: # Returns the maximum token window for the specified OpenAI model.
        official_max_token_window = {
            "gpt-3.5-turbo": 16385,
            "gpt-4-turbo": 128000,
            "gpt-4o": 128000,
            "gpt-4o-mini": 128000,
        }.get(self.OPENAI_MODEL_ID, 128000)

        max_token_window = int(official_max_token_window * 0.90)  # Use 90% of the official limit as a buffer.

        return max_token_window
    
    """
    Loads configuration settings securely from the ZenML secret store.

    This method attempts to retrieve sensitive configuration values (e.g., API keys,
    database URIs, and authentication tokens) stored in ZenMLâ€™s secret management system.
    If the secret store is unavailable or missing, it falls back to default local
    settings, ensuring that the program can still run with safe defaults.

    Returns:
        Settings: The initialized settings object containing environment configuration.
    """

    """
    Ø§ÛŒÙ† Ù…ØªØ¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø§ÛŒÙ…Ù† Ø§Ø² ÙØ¶Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­Ø±Ù…Ø§Ù†Ù‡â€ŒÛŒ Ø°Ù†_Ù…Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

    Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ù…Ø§Ù†Ù†Ø¯ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒØŒ Ø¢Ø¯Ø±Ø³ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒØ¯Ø§Ø¯Ù‡ ÛŒØ§ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø±Ø§ 
    Ø§Ø² Ø¨Ø®Ø´ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø±Ù…Ø² Ø°Ù†_Ù…Ù„ Ø¨Ø®ÙˆØ§Ù†Ø¯ Ùˆ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© Ø´ÛŒØ¡ Ø§Ø² Ú©Ù„Ø§Ø³ Ø³ØªÛŒÙ†Ú¯ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯.  
    Ø§Ú¯Ø± Ø°Ù†_Ù…Ù„ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ù†Ø¯ØŒ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù…Ø­Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯  
    ØªØ§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§ Ø§Ø¯Ø§Ù…Ù‡ ÛŒØ§Ø¨Ø¯.

    Ø®Ø±ÙˆØ¬ÛŒ:
        Ø´ÛŒØ¡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù…Ø­ÛŒØ· Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.
    """
    @classmethod
    def load_settings(cls) -> "Settings":
        """
        Tries to load the settings from the ZenML secret store. If the secret does not exist, it initializes the settings from the .env file and default values.

        Returns:
            Settings: The initialized settings object.
        """

        try:
            logger.info("Trying to load settings from ZenML secret store...")

            settings_secrets = Client().get_secret("settings")
            settings = Settings(**settings_secrets.secret_values)
        except(RuntimeError, KeyError):
            logger.warning(
                "Failed to load settings from the ZenML secret store. Defaulting to loading the settings from the '.env' file."
            )
            settings = Settings()

        return settings
    
    def export(self) -> None:
        """
        Exports the settings to the ZenML secret store.
        it means that the current configuration settings of the application
        are saved securely in ZenML's secret management system.
        """

        env_vars = settings.model_dump()
        for key, value in env_vars.items():
            env_vars[key] = str(value)

        client = Client()

        try:
            client.create_secret(name="settings", values=env_vars)
        except EntityExistsError:
            logger.warning(
                "Secret 'scope' already exists. Delete it manually by running 'zenml secret delete settings', before trying to recreate it."
            )


settings = Settings.load_settings()